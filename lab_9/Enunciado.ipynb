{"cells":[{"cell_type":"markdown","metadata":{"cell_id":"b5c0d2440b3e4995a794ded565213150","deepnote_cell_type":"markdown"},"source":["<h1><center>Laboratorio 9: Optimización de modelos 💯</center></h1>\n","\n","<center><strong>MDS7202: Laboratorio de Programación Científica para Ciencia de Datos</strong></center>"]},{"cell_type":"markdown","metadata":{"cell_id":"bfb94b9656f145ad83e81b75d218cb70","deepnote_cell_type":"markdown"},"source":["### Cuerpo Docente:\n","\n","- Profesor: Ignacio Meza, Gabriel Iturra\n","- Auxiliar: Sebastián Tinoco\n","- Ayudante: Arturo Lazcano, Angelo Muñoz"]},{"cell_type":"markdown","metadata":{"cell_id":"b1b537fdd27c43909a49d3476ce64d91","deepnote_cell_type":"markdown"},"source":["### Equipo: SUPER IMPORTANTE - notebooks sin nombre no serán revisados\n","\n","- Nombre de alumno 1:\n","- Nombre de alumno 2:\n"]},{"cell_type":"markdown","metadata":{"cell_id":"b7dbdd30ab544cb8a8afe00648a586ae","deepnote_cell_type":"markdown"},"source":["## Temas a tratar\n","\n","- Predicción de demanda usando `xgboost`\n","- Búsqueda del modelo óptimo de clasificación usando `optuna`\n","- Uso de pipelines.\n","\n","## Reglas:\n","\n","- **Grupos de 2 personas**\n","- Cualquier duda fuera del horario de clases al foro. Mensajes al equipo docente serán respondidos por este medio.\n","- Prohibidas las copias. \n","- Pueden usar cualquer material del curso que estimen conveniente.\n","\n","### Objetivos principales del laboratorio\n","\n","- Optimizar modelos usando `optuna`\n","- Recurrir a técnicas de *prunning*\n","- Forzar el aprendizaje de relaciones entre variables mediante *constraints*\n","- Fijar un pipeline con un modelo base que luego se irá optimizando.\n","\n","El laboratorio deberá ser desarrollado sin el uso indiscriminado de iteradores nativos de python (aka \"for\", \"while\"). La idea es que aprendan a exprimir al máximo las funciones optimizadas que nos entrega `pandas`, las cuales vale mencionar, son bastante más eficientes que los iteradores nativos sobre DataFrames."]},{"cell_type":"markdown","metadata":{"cell_id":"f38c8342f5164aa992a97488dd5590bf","deepnote_cell_type":"markdown"},"source":["### **Link de repositorio de GitHub:** `http://....`"]},{"cell_type":"markdown","metadata":{"cell_id":"f1c73babb7f74af588a4fa6ae14829e0","deepnote_cell_type":"markdown"},"source":["# Importamos librerias útiles"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"51afe4d2df42442b9e5402ffece60ead","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":4957,"execution_start":1699544354044,"source_hash":null},"outputs":[],"source":["%pip install -qq xgboost optuna"]},{"cell_type":"markdown","metadata":{"cell_id":"44d227389a734ac59189c5e0005bc68a","deepnote_cell_type":"markdown"},"source":["# 1. El emprendimiento de Fiu\n","\n","Tras liderar de manera exitosa la implementación de un proyecto de ciencia de datos para caracterizar los datos generados en Santiago 2023, el misterioso corpóreo **Fiu** se anima y decide levantar su propio negocio de consultoría en machine learning. Tras varias e intensas negociaciones, Fiu logra encontrar su *primera chamba*: predecir la demanda (cantidad de venta) de una famosa productora de bebidas de calibre mundial. Como usted tuvo un rendimiento sobresaliente en el proyecto de caracterización de datos, Fiu lo contrata como *data scientist* de su emprendimiento.\n","\n","Para este laboratorio deben trabajar con los datos `sales.csv` subidos a u-cursos, el cual contiene una muestra de ventas de la empresa para diferentes productos en un determinado tiempo.\n","\n","Para comenzar, cargue el dataset señalado y visualice a través de un `.head` los atributos que posee el dataset.\n","\n","<i><p align=\"center\">Fiu siendo felicitado por su excelente desempeño en el proyecto de caracterización de datos</p></i>\n","<p align=\"center\">\n","  <img src=\"https://media-front.elmostrador.cl/2023/09/A_UNO_1506411_2440e.jpg\">\n","</p>"]},{"cell_type":"code","execution_count":5,"metadata":{"cell_id":"2f9c82d204b14515ad27ae07e0b77702","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":92,"execution_start":1699544359006,"source_hash":null},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>date</th>\n","      <th>city</th>\n","      <th>lat</th>\n","      <th>long</th>\n","      <th>pop</th>\n","      <th>shop</th>\n","      <th>brand</th>\n","      <th>container</th>\n","      <th>capacity</th>\n","      <th>price</th>\n","      <th>quantity</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>2012-01-31</td>\n","      <td>Athens</td>\n","      <td>37.97945</td>\n","      <td>23.71622</td>\n","      <td>672130</td>\n","      <td>shop_1</td>\n","      <td>kinder-cola</td>\n","      <td>glass</td>\n","      <td>500ml</td>\n","      <td>0.96</td>\n","      <td>13280</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>2012-01-31</td>\n","      <td>Athens</td>\n","      <td>37.97945</td>\n","      <td>23.71622</td>\n","      <td>672130</td>\n","      <td>shop_1</td>\n","      <td>kinder-cola</td>\n","      <td>plastic</td>\n","      <td>1.5lt</td>\n","      <td>2.86</td>\n","      <td>6727</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>2012-01-31</td>\n","      <td>Athens</td>\n","      <td>37.97945</td>\n","      <td>23.71622</td>\n","      <td>672130</td>\n","      <td>shop_1</td>\n","      <td>kinder-cola</td>\n","      <td>can</td>\n","      <td>330ml</td>\n","      <td>0.87</td>\n","      <td>9848</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>2012-01-31</td>\n","      <td>Athens</td>\n","      <td>37.97945</td>\n","      <td>23.71622</td>\n","      <td>672130</td>\n","      <td>shop_1</td>\n","      <td>adult-cola</td>\n","      <td>glass</td>\n","      <td>500ml</td>\n","      <td>1.00</td>\n","      <td>20050</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>2012-01-31</td>\n","      <td>Athens</td>\n","      <td>37.97945</td>\n","      <td>23.71622</td>\n","      <td>672130</td>\n","      <td>shop_1</td>\n","      <td>adult-cola</td>\n","      <td>can</td>\n","      <td>330ml</td>\n","      <td>0.39</td>\n","      <td>25696</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   id       date    city       lat      long     pop    shop        brand  \\\n","0   0 2012-01-31  Athens  37.97945  23.71622  672130  shop_1  kinder-cola   \n","1   1 2012-01-31  Athens  37.97945  23.71622  672130  shop_1  kinder-cola   \n","2   2 2012-01-31  Athens  37.97945  23.71622  672130  shop_1  kinder-cola   \n","3   3 2012-01-31  Athens  37.97945  23.71622  672130  shop_1   adult-cola   \n","4   4 2012-01-31  Athens  37.97945  23.71622  672130  shop_1   adult-cola   \n","\n","  container capacity  price  quantity  \n","0     glass    500ml   0.96     13280  \n","1   plastic    1.5lt   2.86      6727  \n","2       can    330ml   0.87      9848  \n","3     glass    500ml   1.00     20050  \n","4       can    330ml   0.39     25696  "]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["import pandas as pd\n","import numpy as np\n","from datetime import datetime\n","\n","df = pd.read_csv('sales.csv')\n","df['date'] = pd.to_datetime(df['date'])\n","\n","df.head()"]},{"cell_type":"markdown","metadata":{"cell_id":"b50db6f2cb804932ae3f9e5748a6ea61","deepnote_cell_type":"markdown"},"source":["## 1.1 Generando un Baseline (0.5 puntos)\n","\n","<p align=\"center\">\n","  <img src=\"https://media.tenor.com/O-lan6TkadUAAAAC/what-i-wnna-do-after-a-baseline.gif\">\n","</p>\n","\n","Antes de entrenar un algoritmo, usted recuerda los apuntes de su magíster en ciencia de datos y recuerda que debe seguir una serie de *buenas prácticas* para entrenar correcta y debidamente su modelo. Después de un par de vueltas, llega a las siguientes tareas:\n","\n","1. Separe los datos en conjuntos de train (70%), validation (20%) y test (10%). Fije una semilla para controlar la aleatoriedad.\n","2. Implemente un `FunctionTransformer` para extraer el día, mes y año de la variable `date`. Guarde estas variables en el formato categorical de pandas.\n","3. Implemente un `ColumnTransformer` para procesar de manera adecuada los datos numéricos y categóricos. Use `OneHotEncoder` para las variables categóricas.\n","4. Guarde los pasos anteriores en un `Pipeline`, dejando como último paso el regresor `DummyRegressor` para generar predicciones en base a promedios.\n","5. Entrene el pipeline anterior y reporte la métrica `mean_absolute_error` sobre los datos de validación. ¿Cómo se interpreta esta métrica para el contexto del negocio?\n","6. Finalmente, vuelva a entrenar el `Pipeline` pero esta vez usando `XGBRegressor` como modelo **utilizando los parámetros por default**. ¿Cómo cambia el MAE al implementar este algoritmo? ¿Es mejor o peor que el `DummyRegressor`?\n","7. Guarde ambos modelos en un archivo .pkl (uno cada uno)"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["MAE con Dummy Regressor: 13413.17673026018\n","MAE con XGBoost: 2427.1128332224994\n"]}],"source":["#1. Separe los datos en conjuntos de train (70%), validation (20%) y test (10%). Fije una semilla para controlar la aleatoriedad.\n","\n","# Paso 1: Separar los datos en conjuntos de train, validation y test\n","from sklearn.model_selection import train_test_split\n","\n","train_data, test_data = train_test_split(df, test_size=0.3, random_state=42)\n","test_data, val_data = train_test_split(test_data, test_size=1/3, random_state=42)\n","\n","#2. Implemente un `FunctionTransformer` para extraer el día, mes y año de la variable `date`. Guarde estas variables en el formato categorical de pandas.\n","\n","# Paso 2: Implementar un FunctionTransformer para extraer el día, mes y año de la variable date\n","from sklearn.preprocessing import FunctionTransformer\n","\n","def extract_date_info(df):\n","    df['day'] = df['date'].dt.day.astype('category')\n","    df['month'] = df['date'].dt.month.astype('category')\n","    df['year'] = df['date'].dt.year.astype('category')\n","    return df.drop('date', axis=1)\n","\n","date_transformer = FunctionTransformer(extract_date_info, validate=False)\n","\n","#3. Implemente un `ColumnTransformer` para procesar de manera adecuada los datos numéricos y categóricos. Use `OneHotEncoder` para las variables categóricas.\n","\n","# Paso 3: Implementar un ColumnTransformer para procesar los datos numéricos y categóricos\n","from sklearn.compose import ColumnTransformer\n","from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n","\n","numeric_features = ['lat', 'long', 'pop', 'price']\n","categorical_features = ['city', 'shop', 'brand', 'container', 'capacity', 'day', 'month', 'year']\n","\n","preprocessor = ColumnTransformer(\n","    transformers=[\n","        ('num', MinMaxScaler(), numeric_features),\n","        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n","    ])\n","\n","#4. Guarde los pasos anteriores en un `Pipeline`, dejando como último paso el regresor `DummyRegressor` para generar predicciones en base a promedios.\n","\n","# Paso 4: Guardar los pasos anteriores en un Pipeline con DummyRegressor\n","from sklearn.pipeline import Pipeline\n","from sklearn.dummy import DummyRegressor\n","\n","pipeline_dummy = Pipeline([\n","    ('date_transformer', date_transformer),\n","    ('preprocessor', preprocessor),\n","    ('regressor', DummyRegressor())\n","])\n","\n","#5. Entrene el pipeline anterior y reporte la métrica `mean_absolute_error` sobre los datos de validación.\n","# ¿Cómo se interpreta esta métrica para el contexto del negocio?\n","\n","# Paso 5: Entrenar el pipeline y reportar la métrica mean_absolute_error sobre los datos de validación\n","from sklearn.metrics import mean_absolute_error, r2_score\n","\n","# Hacemos el split de X e Y para train, validation y testeo\n","X_train = train_data.drop('quantity', axis=1)\n","Y_train = train_data['quantity']\n","X_val = val_data.drop('quantity', axis=1)\n","Y_val = val_data['quantity']\n","X_test = test_data.drop('quantity', axis=1)\n","Y_test = test_data['quantity']\n","\n","pipeline_dummy.fit(X_train, Y_train)\n","val_predictions_dummy = pipeline_dummy.predict(X_val)\n","mae_dummy = mean_absolute_error(Y_val, val_predictions_dummy)\n","r_2_dummy = r2_score(Y_val, val_predictions_dummy)\n","print(f'MAE con Dummy Regressor: {mae_dummy}')\n","\n","# 6. Finalmente, vuelva a entrenar el `Pipeline` pero esta vez usando `XGBRegressor` como modelo **utilizando los parámetros por default**. \n","# ¿Cómo cambia el MAE al implementar este algoritmo? ¿Es mejor o peor que el `DummyRegressor`?\n","\n","# Paso 6: Entrenar el Pipeline con XGBRegressor y reportar el cambio en MAE\n","\n","from xgboost import XGBRegressor\n","from sklearn.metrics import mean_absolute_error, r2_score\n","\n","pipeline_xgb = Pipeline([\n","    ('date_transformer', date_transformer),\n","    ('preprocessor', preprocessor),\n","    ('regressor', XGBRegressor())\n","])\n","\n","pipeline_xgb.fit(X_train, Y_train)\n","val_predictions_xgb = pipeline_xgb.predict(X_val)\n","mae_xgb = mean_absolute_error(Y_val, val_predictions_xgb)\n","r_2_xgb = r2_score(Y_val, val_predictions_xgb)\n","print(f'MAE con XGBoost: {mae_xgb}')\n","\n","#7. Guarde ambos modelos en un archivo .pkl (uno cada uno)\n","\n","# Paso 7: Guardar ambos modelos en un archivo .pkl\n","import pickle\n","\n","with open('regressor_dummy.pkl', 'wb') as f:\n","    pickle.dump(pipeline_dummy, f)\n","\n","with open('regressor_xgb.pkl', 'wb') as f:\n","    pickle.dump(pipeline_xgb, f)"]},{"cell_type":"markdown","metadata":{"cell_id":"7e17e46063774ec28226fe300d42ffe0","deepnote_cell_type":"markdown"},"source":["## 1.2 Forzando relaciones entre parámetros con XGBoost (1.0 puntos)\n","\n","<p align=\"center\">\n","  <img src=\"https://64.media.tumblr.com/14cc45f9610a6ee341a45fd0d68f4dde/20d11b36022bca7b-bf/s640x960/67ab1db12ff73a530f649ac455c000945d99c0d6.gif\">\n","</p>\n","\n","Un colega aficionado a la economía le *sopla* que la demanda guarda una relación inversa con el precio del producto. Motivado para impresionar al querido corpóreo, se propone hacer uso de esta información para mejorar su modelo.\n","\n","Vuelva a entrenar el `Pipeline`, pero esta vez forzando una relación monótona negativa entre el precio y la cantidad. Luego, vuelva a reportar el `MAE` sobre el conjunto de validación. ¿Cómo cambia el error al incluir esta relación? ¿Tenía razón su amigo?\n","\n","Nuevamente, guarde su modelo en un archivo .pkl\n","\n","Nota: Para realizar esta parte, debe apoyarse en la siguiente <a href = https://xgboost.readthedocs.io/en/stable/tutorials/monotonic.html>documentación</a>.\n","\n","Hint: Para implementar el constraint, se le sugiere hacerlo especificando el nombre de la variable. De ser así, probablemente le sea útil **mantener el formato de pandas** antes del step de entrenamiento."]},{"cell_type":"code","execution_count":21,"metadata":{"cell_id":"f469f3b572be434191d2d5c3f11b20d2","deepnote_cell_type":"code"},"outputs":[{"name":"stdout","output_type":"stream","text":["MAE with XGB Regressor: 7251.5476244397205\n","MAE with XGB Regressor and monotonic constraints: 7148.101877984668\n"]}],"source":["from sklearn.pipeline import Pipeline\n","from sklearn.preprocessing import FunctionTransformer, OneHotEncoder, StandardScaler\n","from sklearn.compose import ColumnTransformer\n","from sklearn.model_selection import train_test_split\n","from xgboost import XGBRegressor\n","from sklearn.metrics import mean_absolute_error\n","import pandas as pd\n","import pickle\n","\n","# Prepare the training data\n","X_train = train_data.drop('quantity', axis=1)\n","Y_train = train_data['quantity']\n","X_val = val_data.drop('quantity', axis=1)\n","Y_val = val_data['quantity']\n","X_test = test_data.drop('quantity', axis=1)\n","Y_test = test_data['quantity']\n","\n","# ColumnTransformer\n","numeric_features = ['lat', 'long', 'pop', 'price']\n","categorical_features = ['city', 'shop', 'brand', 'container', 'capacity']\n","preprocessor = ColumnTransformer(\n","    transformers=[\n","        ('num', StandardScaler(), numeric_features),\n","        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n","    ])\n","\n","# Fit the preprocessor\n","X_train_encoded = preprocessor.fit_transform(X_train)\n","X_val_encoded = preprocessor.transform(X_val)\n","\n","# Train the XGBRegressor without constraints\n","model_xgb = XGBRegressor()\n","model_xgb.fit(X_train_encoded, Y_train)\n","val_predictions_xgb = model_xgb.predict(X_val_encoded)\n","mae_xgb = mean_absolute_error(Y_val, val_predictions_xgb)\n","print(f'MAE with XGB Regressor: {mae_xgb}')\n","\n","# Train the XGBRegressor with monotonic constraints\n","monotone_constraints = (0, 1, 0, -1)  # Inversa relación cantidad y precio\n","model_with_constraints = XGBRegressor(monotone_constraints=monotone_constraints)\n","model_with_constraints.fit(X_train_encoded, Y_train)\n","val_predictions_xgb_with_constraints = model_with_constraints.predict(X_val_encoded)\n","mae_xgb_with_constraints = mean_absolute_error(Y_val, val_predictions_xgb_with_constraints)\n","print(f'MAE with XGB Regressor and monotonic constraints: {mae_xgb_with_constraints}')\n","\n","# Save the model with constraints to a .pkl file\n","with open('model_with_constraints.pkl', 'wb') as f:\n","    pickle.dump(model_with_constraints, f)"]},{"cell_type":"markdown","metadata":{"cell_id":"e59ef80ed20b4de8921f24da74e87374","deepnote_cell_type":"markdown"},"source":["## 1.3 Optimización de Hiperparámetros con Optuna (2.0 puntos)\n","\n","<p align=\"center\">\n","  <img src=\"https://media.tenor.com/fmNdyGN4z5kAAAAi/hacking-lucy.gif\">\n","</p>\n","\n","Luego de presentarle sus resultados, Fiu le pregunta si es posible mejorar *aun más* su modelo. En particular, le comenta de la optimización de hiperparámetros con metodologías bayesianas a través del paquete `optuna`. Como usted es un aficionado al entrenamiento de modelos de ML, se propone implementar la descabellada idea de su jefe.\n","\n","A partir de la mejor configuración obtenida en la sección anterior, utilice `optuna` para optimizar sus hiperparámetros. En particular, se le pide:\n","\n","- Fijar una semilla en las instancias necesarias para garantizar la reproducibilidad de resultados\n","- Utilice `TPESampler` como método de muestreo\n","- De `XGBRegressor`, optimice los siguientes hiperparámetros:\n","    - `learning_rate` buscando valores flotantes en el rango (0.001, 0.1)\n","    - `n_estimators` buscando valores enteros en el rango (50, 1000)\n","    - `max_depth` buscando valores enteros en el rango (3, 10)\n","    - `max_leaves` buscando valores enteros en el rango (0, 100)\n","    - `min_child_weight` buscando valores enteros en el rango (1, 5)\n","    - `reg_alpha` buscando valores flotantes en el rango (0, 1)\n","    - `reg_lambda` buscando valores flotantes en el rango (0, 1)\n","- De `OneHotEncoder`, optimice el hiperparámetro `min_frequency` buscando el mejor valor flotante en el rango (0.0, 1.0)\n","- Explique cada hiperparámetro y su rol en el modelo. ¿Hacen sentido los rangos de optimización indicados?\n","- Fije el tiempo de entrenamiento a 5 minutos\n","- Reportar el número de *trials*, el `MAE` y los mejores hiperparámetros encontrados. ¿Cómo cambian sus resultados con respecto a la sección anterior? ¿A qué se puede deber esto?\n","- Guardar su modelo en un archivo .pkl"]},{"cell_type":"code","execution_count":27,"metadata":{"cell_id":"de5914621cc64cb0b1bacb9ff565a97e","deepnote_cell_type":"code"},"outputs":[{"name":"stderr","output_type":"stream","text":["[I 2023-11-15 18:39:22,131] A new study created in memory with name: no-name-6ab888a6-c702-4f81-a39f-6a7385b9ff98\n","[I 2023-11-15 18:39:28,251] Trial 0 finished with value: 7340.164467980445 and parameters: {'learning_rate': 0.03807947176588889, 'n_estimators': 954, 'max_depth': 8, 'max_leaves': 60, 'min_child_weight': 1, 'reg_alpha': 0.15599452033620265, 'reg_lambda': 0.05808361216819946}. Best is trial 0 with value: 7340.164467980445.\n","[I 2023-11-15 18:39:29,134] Trial 1 finished with value: 7368.967186302527 and parameters: {'learning_rate': 0.08675143843171859, 'n_estimators': 621, 'max_depth': 8, 'max_leaves': 2, 'min_child_weight': 5, 'reg_alpha': 0.8324426408004217, 'reg_lambda': 0.21233911067827616}. Best is trial 0 with value: 7340.164467980445.\n","[I 2023-11-15 18:39:30,068] Trial 2 finished with value: 6854.089796030818 and parameters: {'learning_rate': 0.01900067175350296, 'n_estimators': 224, 'max_depth': 5, 'max_leaves': 53, 'min_child_weight': 3, 'reg_alpha': 0.2912291401980419, 'reg_lambda': 0.6118528947223795}. Best is trial 2 with value: 6854.089796030818.\n","[I 2023-11-15 18:39:31,551] Trial 3 finished with value: 6820.983722676299 and parameters: {'learning_rate': 0.01480989220455214, 'n_estimators': 327, 'max_depth': 5, 'max_leaves': 46, 'min_child_weight': 4, 'reg_alpha': 0.19967378215835974, 'reg_lambda': 0.5142344384136116}. Best is trial 3 with value: 6820.983722676299.\n","[I 2023-11-15 18:39:32,004] Trial 4 finished with value: 6826.263682608388 and parameters: {'learning_rate': 0.05964904231734221, 'n_estimators': 94, 'max_depth': 7, 'max_leaves': 17, 'min_child_weight': 1, 'reg_alpha': 0.9488855372533332, 'reg_lambda': 0.9656320330745594}. Best is trial 3 with value: 6820.983722676299.\n","[I 2023-11-15 18:39:33,016] Trial 5 finished with value: 6682.336677100904 and parameters: {'learning_rate': 0.08103133746352965, 'n_estimators': 339, 'max_depth': 3, 'max_leaves': 69, 'min_child_weight': 3, 'reg_alpha': 0.12203823484477883, 'reg_lambda': 0.4951769101112702}. Best is trial 5 with value: 6682.336677100904.\n","[I 2023-11-15 18:39:36,974] Trial 6 finished with value: 6868.945204793755 and parameters: {'learning_rate': 0.004404463590406622, 'n_estimators': 914, 'max_depth': 5, 'max_leaves': 66, 'min_child_weight': 2, 'reg_alpha': 0.5200680211778108, 'reg_lambda': 0.5467102793432796}. Best is trial 5 with value: 6682.336677100904.\n","[I 2023-11-15 18:39:44,893] Trial 7 finished with value: 7142.8119217350595 and parameters: {'learning_rate': 0.01930059109702718, 'n_estimators': 972, 'max_depth': 9, 'max_leaves': 94, 'min_child_weight': 5, 'reg_alpha': 0.5978999788110851, 'reg_lambda': 0.9218742350231168}. Best is trial 5 with value: 6682.336677100904.\n","[I 2023-11-15 18:39:45,543] Trial 8 finished with value: 8036.605985107561 and parameters: {'learning_rate': 0.00976075770314003, 'n_estimators': 236, 'max_depth': 3, 'max_leaves': 32, 'min_child_weight': 2, 'reg_alpha': 0.2713490317738959, 'reg_lambda': 0.8287375091519293}. Best is trial 5 with value: 6682.336677100904.\n","[I 2023-11-15 18:39:46,655] Trial 9 finished with value: 6698.610868215479 and parameters: {'learning_rate': 0.036318579342665344, 'n_estimators': 317, 'max_depth': 7, 'max_leaves': 14, 'min_child_weight': 5, 'reg_alpha': 0.07455064367977082, 'reg_lambda': 0.9868869366005173}. Best is trial 5 with value: 6682.336677100904.\n","[I 2023-11-15 18:39:48,122] Trial 10 finished with value: 6720.094321118466 and parameters: {'learning_rate': 0.09766627133786099, 'n_estimators': 581, 'max_depth': 3, 'max_leaves': 87, 'min_child_weight': 3, 'reg_alpha': 0.038725199961183066, 'reg_lambda': 0.3310460817165841}. Best is trial 5 with value: 6682.336677100904.\n","[I 2023-11-15 18:39:51,493] Trial 11 finished with value: 7304.361824867761 and parameters: {'learning_rate': 0.06570573457633735, 'n_estimators': 451, 'max_depth': 10, 'max_leaves': 77, 'min_child_weight': 4, 'reg_alpha': 0.02396004615234537, 'reg_lambda': 0.7325127315289228}. Best is trial 5 with value: 6682.336677100904.\n","[I 2023-11-15 18:39:53,632] Trial 12 finished with value: 6821.529334861936 and parameters: {'learning_rate': 0.04100311017021925, 'n_estimators': 420, 'max_depth': 6, 'max_leaves': 34, 'min_child_weight': 4, 'reg_alpha': 0.3694310722175758, 'reg_lambda': 0.7380364464431612}. Best is trial 5 with value: 6682.336677100904.\n","[I 2023-11-15 18:39:54,572] Trial 13 finished with value: 7365.068678208014 and parameters: {'learning_rate': 0.0730869413784018, 'n_estimators': 722, 'max_depth': 4, 'max_leaves': 2, 'min_child_weight': 2, 'reg_alpha': 0.0039412809716702635, 'reg_lambda': 0.4123415768769636}. Best is trial 5 with value: 6682.336677100904.\n","[I 2023-11-15 18:39:55,033] Trial 14 finished with value: 6915.273094508176 and parameters: {'learning_rate': 0.05190806939414569, 'n_estimators': 55, 'max_depth': 7, 'max_leaves': 74, 'min_child_weight': 4, 'reg_alpha': 0.1194517826723152, 'reg_lambda': 0.9953148494576313}. Best is trial 5 with value: 6682.336677100904.\n","[I 2023-11-15 18:39:56,859] Trial 15 finished with value: 6906.5409861915 and parameters: {'learning_rate': 0.07763375864749647, 'n_estimators': 301, 'max_depth': 6, 'max_leaves': 40, 'min_child_weight': 5, 'reg_alpha': 0.39641415124816637, 'reg_lambda': 0.6512279310422994}. Best is trial 5 with value: 6682.336677100904.\n","[I 2023-11-15 18:39:58,698] Trial 16 finished with value: 6690.810057615208 and parameters: {'learning_rate': 0.034539549006929356, 'n_estimators': 430, 'max_depth': 8, 'max_leaves': 15, 'min_child_weight': 3, 'reg_alpha': 0.1472988683354317, 'reg_lambda': 0.4470554005939228}. Best is trial 5 with value: 6682.336677100904.\n","[I 2023-11-15 18:40:01,965] Trial 17 finished with value: 6869.24507204947 and parameters: {'learning_rate': 0.049595977525082095, 'n_estimators': 718, 'max_depth': 10, 'max_leaves': 21, 'min_child_weight': 3, 'reg_alpha': 0.19237503196221592, 'reg_lambda': 0.4170147349231994}. Best is trial 5 with value: 6682.336677100904.\n","[I 2023-11-15 18:40:05,136] Trial 18 finished with value: 7480.97464618138 and parameters: {'learning_rate': 0.09722205452554573, 'n_estimators': 470, 'max_depth': 9, 'max_leaves': 58, 'min_child_weight': 3, 'reg_alpha': 0.27382956815385967, 'reg_lambda': 0.31345818247487006}. Best is trial 5 with value: 6682.336677100904.\n","[I 2023-11-15 18:40:05,687] Trial 19 finished with value: 7012.732088802231 and parameters: {'learning_rate': 0.02832073140281637, 'n_estimators': 143, 'max_depth': 4, 'max_leaves': 80, 'min_child_weight': 2, 'reg_alpha': 0.1314497956179423, 'reg_lambda': 0.5067762568716672}. Best is trial 5 with value: 6682.336677100904.\n","[I 2023-11-15 18:40:09,492] Trial 20 finished with value: 7456.99758957161 and parameters: {'learning_rate': 0.06073043980418224, 'n_estimators': 546, 'max_depth': 8, 'max_leaves': 97, 'min_child_weight': 2, 'reg_alpha': 0.0003168152264794444, 'reg_lambda': 0.6041585495011994}. Best is trial 5 with value: 6682.336677100904.\n","[I 2023-11-15 18:40:10,837] Trial 21 finished with value: 6713.323920365231 and parameters: {'learning_rate': 0.029556992404318236, 'n_estimators': 320, 'max_depth': 7, 'max_leaves': 17, 'min_child_weight': 3, 'reg_alpha': 0.10639078516612782, 'reg_lambda': 0.8165352680105369}. Best is trial 5 with value: 6682.336677100904.\n","[I 2023-11-15 18:40:12,544] Trial 22 finished with value: 6750.813859927306 and parameters: {'learning_rate': 0.04375392081396803, 'n_estimators': 389, 'max_depth': 9, 'max_leaves': 25, 'min_child_weight': 4, 'reg_alpha': 0.07138691120605827, 'reg_lambda': 0.44376685525400084}. Best is trial 5 with value: 6682.336677100904.\n","[I 2023-11-15 18:40:13,333] Trial 23 finished with value: 6964.8750001398175 and parameters: {'learning_rate': 0.028851160183491893, 'n_estimators': 210, 'max_depth': 6, 'max_leaves': 10, 'min_child_weight': 3, 'reg_alpha': 0.15007730857488896, 'reg_lambda': 0.6382824223638552}. Best is trial 5 with value: 6682.336677100904.\n","[I 2023-11-15 18:40:15,195] Trial 24 finished with value: 6748.475052824537 and parameters: {'learning_rate': 0.03535536152664565, 'n_estimators': 369, 'max_depth': 8, 'max_leaves': 29, 'min_child_weight': 4, 'reg_alpha': 0.08327713531004559, 'reg_lambda': 0.564076648684998}. Best is trial 5 with value: 6682.336677100904.\n","[I 2023-11-15 18:40:16,690] Trial 25 finished with value: 6652.441920213266 and parameters: {'learning_rate': 0.04975034550839093, 'n_estimators': 487, 'max_depth': 7, 'max_leaves': 9, 'min_child_weight': 3, 'reg_alpha': 0.22274067483389282, 'reg_lambda': 0.7064979268337808}. Best is trial 25 with value: 6652.441920213266.\n","[I 2023-11-15 18:40:18,262] Trial 26 finished with value: 6661.600138040172 and parameters: {'learning_rate': 0.05106319853314855, 'n_estimators': 494, 'max_depth': 4, 'max_leaves': 9, 'min_child_weight': 3, 'reg_alpha': 0.22282975298923674, 'reg_lambda': 0.47919432209011725}. Best is trial 25 with value: 6652.441920213266.\n","[I 2023-11-15 18:40:20,499] Trial 27 finished with value: 6771.614096178202 and parameters: {'learning_rate': 0.05320698373408816, 'n_estimators': 650, 'max_depth': 4, 'max_leaves': 41, 'min_child_weight': 3, 'reg_alpha': 0.24967767421561723, 'reg_lambda': 0.7051357659688804}. Best is trial 25 with value: 6652.441920213266.\n","[I 2023-11-15 18:40:22,004] Trial 28 finished with value: 6699.414158023115 and parameters: {'learning_rate': 0.07474404050956954, 'n_estimators': 493, 'max_depth': 3, 'max_leaves': 6, 'min_child_weight': 2, 'reg_alpha': 0.36059630877014603, 'reg_lambda': 0.548319220283982}. Best is trial 25 with value: 6652.441920213266.\n","[I 2023-11-15 18:40:25,536] Trial 29 finished with value: 6780.979425996004 and parameters: {'learning_rate': 0.046076382659056246, 'n_estimators': 840, 'max_depth': 4, 'max_leaves': 64, 'min_child_weight': 1, 'reg_alpha': 0.1970626346169713, 'reg_lambda': 0.21881522313952434}. Best is trial 25 with value: 6652.441920213266.\n","[I 2023-11-15 18:40:26,902] Trial 30 finished with value: 6671.696025958181 and parameters: {'learning_rate': 0.06761063267479214, 'n_estimators': 504, 'max_depth': 3, 'max_leaves': 51, 'min_child_weight': 3, 'reg_alpha': 0.21076135130202897, 'reg_lambda': 0.022004336963113325}. Best is trial 25 with value: 6652.441920213266.\n","[I 2023-11-15 18:40:28,339] Trial 31 finished with value: 6671.849410516841 and parameters: {'learning_rate': 0.05779820154826187, 'n_estimators': 542, 'max_depth': 3, 'max_leaves': 53, 'min_child_weight': 3, 'reg_alpha': 0.2231815637033503, 'reg_lambda': 0.034215926670917274}. Best is trial 25 with value: 6652.441920213266.\n","[I 2023-11-15 18:40:29,764] Trial 32 finished with value: 6670.465788877521 and parameters: {'learning_rate': 0.057632638614797026, 'n_estimators': 540, 'max_depth': 3, 'max_leaves': 56, 'min_child_weight': 3, 'reg_alpha': 0.32028550842462955, 'reg_lambda': 0.007213108470602882}. Best is trial 25 with value: 6652.441920213266.\n","[I 2023-11-15 18:40:32,484] Trial 33 finished with value: 7043.729193197005 and parameters: {'learning_rate': 0.06653419318336068, 'n_estimators': 654, 'max_depth': 5, 'max_leaves': 46, 'min_child_weight': 3, 'reg_alpha': 0.3213291097403035, 'reg_lambda': 0.089109467746576}. Best is trial 25 with value: 6652.441920213266.\n","[I 2023-11-15 18:40:34,512] Trial 34 finished with value: 6738.421185681536 and parameters: {'learning_rate': 0.04871112020290585, 'n_estimators': 611, 'max_depth': 4, 'max_leaves': 58, 'min_child_weight': 4, 'reg_alpha': 0.32277355395567175, 'reg_lambda': 0.09874919453333907}. Best is trial 25 with value: 6652.441920213266.\n","[I 2023-11-15 18:40:37,467] Trial 35 finished with value: 7026.975693062066 and parameters: {'learning_rate': 0.05568822502544019, 'n_estimators': 720, 'max_depth': 5, 'max_leaves': 47, 'min_child_weight': 2, 'reg_alpha': 0.254764679098868, 'reg_lambda': 0.03823269644049662}. Best is trial 25 with value: 6652.441920213266.\n","[I 2023-11-15 18:40:38,761] Trial 36 finished with value: 6677.698376659503 and parameters: {'learning_rate': 0.06294515459228739, 'n_estimators': 504, 'max_depth': 3, 'max_leaves': 40, 'min_child_weight': 4, 'reg_alpha': 0.43321918699424083, 'reg_lambda': 0.1278213109887625}. Best is trial 25 with value: 6652.441920213266.\n","[I 2023-11-15 18:40:40,651] Trial 37 finished with value: 6769.872213957387 and parameters: {'learning_rate': 0.0559270501186394, 'n_estimators': 565, 'max_depth': 4, 'max_leaves': 51, 'min_child_weight': 3, 'reg_alpha': 0.18355036298950245, 'reg_lambda': 0.17163241878786137}. Best is trial 25 with value: 6652.441920213266.\n","[I 2023-11-15 18:40:41,911] Trial 38 finished with value: 6661.789820432414 and parameters: {'learning_rate': 0.0673446057832526, 'n_estimators': 517, 'max_depth': 5, 'max_leaves': 8, 'min_child_weight': 1, 'reg_alpha': 0.2229831427104597, 'reg_lambda': 0.013253609506721387}. Best is trial 25 with value: 6652.441920213266.\n","[I 2023-11-15 18:40:44,697] Trial 39 finished with value: 6927.6883803968885 and parameters: {'learning_rate': 0.04538875415298672, 'n_estimators': 657, 'max_depth': 5, 'max_leaves': 0, 'min_child_weight': 1, 'reg_alpha': 0.33007919888010445, 'reg_lambda': 0.0122860853469373}. Best is trial 25 with value: 6652.441920213266.\n","[I 2023-11-15 18:40:46,757] Trial 40 finished with value: 6691.724657826811 and parameters: {'learning_rate': 0.059276071097408414, 'n_estimators': 799, 'max_depth': 6, 'max_leaves': 7, 'min_child_weight': 1, 'reg_alpha': 0.294881718485903, 'reg_lambda': 0.158365460544985}. Best is trial 25 with value: 6652.441920213266.\n","[I 2023-11-15 18:40:48,080] Trial 41 finished with value: 6648.874496910657 and parameters: {'learning_rate': 0.06825700802126608, 'n_estimators': 501, 'max_depth': 3, 'max_leaves': 24, 'min_child_weight': 2, 'reg_alpha': 0.2260189143669869, 'reg_lambda': 0.008864090343279965}. Best is trial 41 with value: 6648.874496910657.\n","[I 2023-11-15 18:40:49,929] Trial 42 finished with value: 6712.621177984224 and parameters: {'learning_rate': 0.07048274159088275, 'n_estimators': 605, 'max_depth': 4, 'max_leaves': 11, 'min_child_weight': 1, 'reg_alpha': 0.22836689309803335, 'reg_lambda': 0.0706151330041032}. Best is trial 41 with value: 6648.874496910657.\n","[I 2023-11-15 18:40:51,026] Trial 43 finished with value: 6663.043942257682 and parameters: {'learning_rate': 0.06329053578949356, 'n_estimators': 403, 'max_depth': 3, 'max_leaves': 22, 'min_child_weight': 2, 'reg_alpha': 0.28121787037602075, 'reg_lambda': 0.07692230636132294}. Best is trial 41 with value: 6648.874496910657.\n","[I 2023-11-15 18:40:52,204] Trial 44 finished with value: 6688.497545483466 and parameters: {'learning_rate': 0.06359008944005828, 'n_estimators': 259, 'max_depth': 5, 'max_leaves': 23, 'min_child_weight': 1, 'reg_alpha': 0.17700115339169128, 'reg_lambda': 0.2316649541237172}. Best is trial 41 with value: 6648.874496910657.\n","[I 2023-11-15 18:40:52,974] Trial 45 finished with value: 6893.504008109293 and parameters: {'learning_rate': 0.06925517815193036, 'n_estimators': 373, 'max_depth': 4, 'max_leaves': 4, 'min_child_weight': 2, 'reg_alpha': 0.25295979679509095, 'reg_lambda': 0.07933724875824488}. Best is trial 41 with value: 6648.874496910657.\n","[I 2023-11-15 18:40:54,152] Trial 46 finished with value: 6672.2872767170165 and parameters: {'learning_rate': 0.06453744274714196, 'n_estimators': 407, 'max_depth': 3, 'max_leaves': 19, 'min_child_weight': 2, 'reg_alpha': 0.4236835147242234, 'reg_lambda': 0.10727389431225098}. Best is trial 41 with value: 6648.874496910657.\n","[I 2023-11-15 18:40:55,592] Trial 47 finished with value: 6675.877099154497 and parameters: {'learning_rate': 0.08388245571357578, 'n_estimators': 462, 'max_depth': 3, 'max_leaves': 27, 'min_child_weight': 1, 'reg_alpha': 0.06169182876513782, 'reg_lambda': 0.06360846978580083}. Best is trial 41 with value: 6648.874496910657.\n","[I 2023-11-15 18:40:57,325] Trial 48 finished with value: 6666.004742706276 and parameters: {'learning_rate': 0.05315033209149797, 'n_estimators': 456, 'max_depth': 5, 'max_leaves': 11, 'min_child_weight': 2, 'reg_alpha': 0.2855304024327555, 'reg_lambda': 0.1531107742139967}. Best is trial 41 with value: 6648.874496910657.\n","[I 2023-11-15 18:40:58,821] Trial 49 finished with value: 6823.3771350174475 and parameters: {'learning_rate': 0.07224823511140162, 'n_estimators': 284, 'max_depth': 7, 'max_leaves': 31, 'min_child_weight': 2, 'reg_alpha': 0.16777939207463047, 'reg_lambda': 0.2678762434039914}. Best is trial 41 with value: 6648.874496910657.\n","[I 2023-11-15 18:41:00,106] Trial 50 finished with value: 6690.679010954341 and parameters: {'learning_rate': 0.07752775313316732, 'n_estimators': 364, 'max_depth': 6, 'max_leaves': 13, 'min_child_weight': 1, 'reg_alpha': 0.11648078965321396, 'reg_lambda': 0.1221643052637515}. Best is trial 41 with value: 6648.874496910657.\n","[I 2023-11-15 18:41:01,609] Trial 51 finished with value: 6652.389059147611 and parameters: {'learning_rate': 0.05278757355949321, 'n_estimators': 441, 'max_depth': 5, 'max_leaves': 9, 'min_child_weight': 2, 'reg_alpha': 0.2829161943186158, 'reg_lambda': 0.1693846077835716}. Best is trial 41 with value: 6648.874496910657.\n","[I 2023-11-15 18:41:02,751] Trial 52 finished with value: 6715.492839926568 and parameters: {'learning_rate': 0.0604389872923622, 'n_estimators': 437, 'max_depth': 4, 'max_leaves': 6, 'min_child_weight': 2, 'reg_alpha': 0.25514554571157916, 'reg_lambda': 0.18443877777173398}. Best is trial 41 with value: 6648.874496910657.\n","[I 2023-11-15 18:41:04,784] Trial 53 finished with value: 6760.346217173555 and parameters: {'learning_rate': 0.05003147527436703, 'n_estimators': 487, 'max_depth': 5, 'max_leaves': 20, 'min_child_weight': 2, 'reg_alpha': 0.20090493122018735, 'reg_lambda': 0.0028012510131561457}. Best is trial 41 with value: 6648.874496910657.\n","[I 2023-11-15 18:41:06,900] Trial 54 finished with value: 6699.2849304491365 and parameters: {'learning_rate': 0.040357173906889886, 'n_estimators': 576, 'max_depth': 6, 'max_leaves': 16, 'min_child_weight': 2, 'reg_alpha': 0.14564033506235838, 'reg_lambda': 0.07408741524143367}. Best is trial 41 with value: 6648.874496910657.\n","[I 2023-11-15 18:41:08,496] Trial 55 finished with value: 6732.170071484416 and parameters: {'learning_rate': 0.06774405998930502, 'n_estimators': 413, 'max_depth': 4, 'max_leaves': 35, 'min_child_weight': 2, 'reg_alpha': 0.29255449140316153, 'reg_lambda': 0.04881840615107115}. Best is trial 41 with value: 6648.874496910657.\n","[I 2023-11-15 18:41:09,453] Trial 56 finished with value: 6707.044819085325 and parameters: {'learning_rate': 0.05442640835198997, 'n_estimators': 343, 'max_depth': 3, 'max_leaves': 0, 'min_child_weight': 1, 'reg_alpha': 0.23048747451969878, 'reg_lambda': 0.37665952331478586}. Best is trial 41 with value: 6648.874496910657.\n","[I 2023-11-15 18:41:11,044] Trial 57 finished with value: 6664.925721854313 and parameters: {'learning_rate': 0.06163135238149061, 'n_estimators': 511, 'max_depth': 5, 'max_leaves': 9, 'min_child_weight': 3, 'reg_alpha': 0.3594047594122242, 'reg_lambda': 0.13068310452877024}. Best is trial 41 with value: 6648.874496910657.\n","[I 2023-11-15 18:41:12,835] Trial 58 finished with value: 6777.681026547963 and parameters: {'learning_rate': 0.04824132257621334, 'n_estimators': 444, 'max_depth': 7, 'max_leaves': 24, 'min_child_weight': 2, 'reg_alpha': 0.49638632212542644, 'reg_lambda': 0.20267032063848958}. Best is trial 41 with value: 6648.874496910657.\n","[I 2023-11-15 18:41:14,574] Trial 59 finished with value: 6698.766244302009 and parameters: {'learning_rate': 0.05124626493803673, 'n_estimators': 524, 'max_depth': 4, 'max_leaves': 17, 'min_child_weight': 1, 'reg_alpha': 0.09759583562054505, 'reg_lambda': 0.13556599732166502}. Best is trial 41 with value: 6648.874496910657.\n","[I 2023-11-15 18:41:15,331] Trial 60 finished with value: 6679.091903903592 and parameters: {'learning_rate': 0.062862675149864, 'n_estimators': 206, 'max_depth': 7, 'max_leaves': 14, 'min_child_weight': 2, 'reg_alpha': 0.15146669814147806, 'reg_lambda': 0.27490721281871533}. Best is trial 41 with value: 6648.874496910657.\n","[I 2023-11-15 18:41:16,573] Trial 61 finished with value: 6695.117194180924 and parameters: {'learning_rate': 0.061727761005425624, 'n_estimators': 519, 'max_depth': 5, 'max_leaves': 7, 'min_child_weight': 3, 'reg_alpha': 0.36720354830781493, 'reg_lambda': 0.1037887004555616}. Best is trial 41 with value: 6648.874496910657.\n","[I 2023-11-15 18:41:17,469] Trial 62 finished with value: 7022.671099344941 and parameters: {'learning_rate': 0.05664982983845277, 'n_estimators': 469, 'max_depth': 5, 'max_leaves': 3, 'min_child_weight': 3, 'reg_alpha': 0.2735470758404268, 'reg_lambda': 0.042703831855195495}. Best is trial 41 with value: 6648.874496910657.\n","[I 2023-11-15 18:41:19,519] Trial 63 finished with value: 6695.754587415329 and parameters: {'learning_rate': 0.06536566116843402, 'n_estimators': 593, 'max_depth': 6, 'max_leaves': 10, 'min_child_weight': 3, 'reg_alpha': 0.2201494266141526, 'reg_lambda': 0.13860986734164887}. Best is trial 41 with value: 6648.874496910657.\n","[I 2023-11-15 18:41:20,865] Trial 64 finished with value: 6656.72488435815 and parameters: {'learning_rate': 0.05835310426064199, 'n_estimators': 399, 'max_depth': 4, 'max_leaves': 9, 'min_child_weight': 3, 'reg_alpha': 0.34769475349366763, 'reg_lambda': 0.18956084559526784}. Best is trial 41 with value: 6648.874496910657.\n","[I 2023-11-15 18:41:21,864] Trial 65 finished with value: 6683.236631308764 and parameters: {'learning_rate': 0.05232815882148059, 'n_estimators': 405, 'max_depth': 3, 'max_leaves': 22, 'min_child_weight': 3, 'reg_alpha': 0.18199813547269592, 'reg_lambda': 0.4919178392939371}. Best is trial 41 with value: 6648.874496910657.\n","[I 2023-11-15 18:41:22,580] Trial 66 finished with value: 7088.276041966301 and parameters: {'learning_rate': 0.05798945256421496, 'n_estimators': 354, 'max_depth': 4, 'max_leaves': 3, 'min_child_weight': 4, 'reg_alpha': 0.30005192140457276, 'reg_lambda': 0.1796745835503517}. Best is trial 41 with value: 6648.874496910657.\n","[I 2023-11-15 18:41:23,453] Trial 67 finished with value: 6687.090842061332 and parameters: {'learning_rate': 0.07106504974044713, 'n_estimators': 295, 'max_depth': 3, 'max_leaves': 18, 'min_child_weight': 3, 'reg_alpha': 0.2327375936743491, 'reg_lambda': 0.05283059249395166}. Best is trial 41 with value: 6648.874496910657.\n","[I 2023-11-15 18:41:25,242] Trial 68 finished with value: 6687.135717340263 and parameters: {'learning_rate': 0.045206294614251324, 'n_estimators': 557, 'max_depth': 4, 'max_leaves': 13, 'min_child_weight': 2, 'reg_alpha': 0.27068689554389275, 'reg_lambda': 0.08200351553534331}. Best is trial 41 with value: 6648.874496910657.\n","[I 2023-11-15 18:41:26,248] Trial 69 finished with value: 6692.024904069631 and parameters: {'learning_rate': 0.05444129675214978, 'n_estimators': 392, 'max_depth': 3, 'max_leaves': 26, 'min_child_weight': 5, 'reg_alpha': 0.20746476306796044, 'reg_lambda': 0.3704798702172615}. Best is trial 41 with value: 6648.874496910657.\n","[I 2023-11-15 18:41:27,396] Trial 70 finished with value: 6681.949245363295 and parameters: {'learning_rate': 0.06698021802095722, 'n_estimators': 433, 'max_depth': 8, 'max_leaves': 8, 'min_child_weight': 4, 'reg_alpha': 0.34052669608074804, 'reg_lambda': 0.010155521223214508}. Best is trial 41 with value: 6648.874496910657.\n","[I 2023-11-15 18:41:28,853] Trial 71 finished with value: 6669.853225330628 and parameters: {'learning_rate': 0.05921758956135469, 'n_estimators': 484, 'max_depth': 5, 'max_leaves': 9, 'min_child_weight': 3, 'reg_alpha': 0.35200111542991364, 'reg_lambda': 0.12360462587613413}. Best is trial 41 with value: 6648.874496910657.\n","[I 2023-11-15 18:41:30,079] Trial 72 finished with value: 6735.526918022841 and parameters: {'learning_rate': 0.06157849513179245, 'n_estimators': 531, 'max_depth': 6, 'max_leaves': 5, 'min_child_weight': 3, 'reg_alpha': 0.3017709034439785, 'reg_lambda': 0.15849322538773958}. Best is trial 41 with value: 6648.874496910657.\n","[I 2023-11-15 18:41:31,709] Trial 73 finished with value: 6670.197927199432 and parameters: {'learning_rate': 0.04816015312612307, 'n_estimators': 514, 'max_depth': 4, 'max_leaves': 12, 'min_child_weight': 3, 'reg_alpha': 0.37599122377432653, 'reg_lambda': 0.20358074498426482}. Best is trial 41 with value: 6648.874496910657.\n","[I 2023-11-15 18:41:33,698] Trial 74 finished with value: 6846.355565083455 and parameters: {'learning_rate': 0.0756582782799963, 'n_estimators': 634, 'max_depth': 5, 'max_leaves': 15, 'min_child_weight': 3, 'reg_alpha': 0.241979173690187, 'reg_lambda': 0.04320573777856951}. Best is trial 41 with value: 6648.874496910657.\n","[I 2023-11-15 18:41:34,258] Trial 75 finished with value: 13560.446601880485 and parameters: {'learning_rate': 0.06877165429784811, 'n_estimators': 478, 'max_depth': 5, 'max_leaves': 1, 'min_child_weight': 3, 'reg_alpha': 0.26707383523022077, 'reg_lambda': 0.10991052081945084}. Best is trial 41 with value: 6648.874496910657.\n","[I 2023-11-15 18:41:35,261] Trial 76 finished with value: 6681.745709861348 and parameters: {'learning_rate': 0.0655125414059717, 'n_estimators': 330, 'max_depth': 4, 'max_leaves': 20, 'min_child_weight': 2, 'reg_alpha': 0.31282262591630855, 'reg_lambda': 0.23968529856633058}. Best is trial 41 with value: 6648.874496910657.\n","[I 2023-11-15 18:41:36,537] Trial 77 finished with value: 6660.701781336 and parameters: {'learning_rate': 0.05607915242217314, 'n_estimators': 427, 'max_depth': 7, 'max_leaves': 10, 'min_child_weight': 3, 'reg_alpha': 0.3343900982197965, 'reg_lambda': 0.08677343380505556}. Best is trial 41 with value: 6648.874496910657.\n","[I 2023-11-15 18:41:37,444] Trial 78 finished with value: 6798.131175200897 and parameters: {'learning_rate': 0.05571985061180407, 'n_estimators': 392, 'max_depth': 7, 'max_leaves': 5, 'min_child_weight': 3, 'reg_alpha': 0.17891079159369194, 'reg_lambda': 0.02178294209344324}. Best is trial 41 with value: 6648.874496910657.\n","[I 2023-11-15 18:41:39,521] Trial 79 finished with value: 6888.502945523462 and parameters: {'learning_rate': 0.05190401562061243, 'n_estimators': 437, 'max_depth': 7, 'max_leaves': 34, 'min_child_weight': 4, 'reg_alpha': 0.208593048504905, 'reg_lambda': 0.08311526776973269}. Best is trial 41 with value: 6648.874496910657.\n","[I 2023-11-15 18:41:41,012] Trial 80 finished with value: 6737.724186805482 and parameters: {'learning_rate': 0.04313673676747676, 'n_estimators': 373, 'max_depth': 9, 'max_leaves': 29, 'min_child_weight': 2, 'reg_alpha': 0.12692359390709407, 'reg_lambda': 0.06627644069222441}. Best is trial 41 with value: 6648.874496910657.\n","[I 2023-11-15 18:41:42,503] Trial 81 finished with value: 6675.234529225006 and parameters: {'learning_rate': 0.06012884991421022, 'n_estimators': 495, 'max_depth': 7, 'max_leaves': 9, 'min_child_weight': 3, 'reg_alpha': 0.4061798272087693, 'reg_lambda': 0.13869514514539413}. Best is trial 41 with value: 6648.874496910657.\n","[I 2023-11-15 18:41:43,879] Trial 82 finished with value: 6720.184189172799 and parameters: {'learning_rate': 0.05810248459974939, 'n_estimators': 420, 'max_depth': 6, 'max_leaves': 15, 'min_child_weight': 3, 'reg_alpha': 0.33223679906960396, 'reg_lambda': 0.18483753380145718}. Best is trial 41 with value: 6648.874496910657.\n","[I 2023-11-15 18:41:44,987] Trial 83 finished with value: 6669.965332126853 and parameters: {'learning_rate': 0.06316387073996575, 'n_estimators': 458, 'max_depth': 3, 'max_leaves': 12, 'min_child_weight': 3, 'reg_alpha': 0.2826648464452564, 'reg_lambda': 0.00017853065185354997}. Best is trial 41 with value: 6648.874496910657.\n","[I 2023-11-15 18:41:45,975] Trial 84 finished with value: 6993.940597899721 and parameters: {'learning_rate': 0.05382781560444055, 'n_estimators': 554, 'max_depth': 8, 'max_leaves': 3, 'min_child_weight': 3, 'reg_alpha': 0.2536680568923646, 'reg_lambda': 0.09410440104726897}. Best is trial 41 with value: 6648.874496910657.\n","[I 2023-11-15 18:41:47,226] Trial 85 finished with value: 6675.830200932158 and parameters: {'learning_rate': 0.04976714383048221, 'n_estimators': 505, 'max_depth': 6, 'max_leaves': 8, 'min_child_weight': 3, 'reg_alpha': 0.34548620557226856, 'reg_lambda': 0.030882758583625356}. Best is trial 41 with value: 6648.874496910657.\n","[I 2023-11-15 18:41:48,979] Trial 86 finished with value: 6824.580574504315 and parameters: {'learning_rate': 0.07300191430154603, 'n_estimators': 581, 'max_depth': 4, 'max_leaves': 18, 'min_child_weight': 2, 'reg_alpha': 0.36968978285828824, 'reg_lambda': 0.16199843530233343}. Best is trial 41 with value: 6648.874496910657.\n","[I 2023-11-15 18:41:50,274] Trial 87 finished with value: 6651.882713121726 and parameters: {'learning_rate': 0.05665679795914826, 'n_estimators': 460, 'max_depth': 7, 'max_leaves': 10, 'min_child_weight': 3, 'reg_alpha': 0.3153993647833226, 'reg_lambda': 0.10530663838663698}. Best is trial 41 with value: 6648.874496910657.\n","[I 2023-11-15 18:41:54,546] Trial 88 finished with value: 7204.1225136294615 and parameters: {'learning_rate': 0.047328429470862535, 'n_estimators': 935, 'max_depth': 7, 'max_leaves': 37, 'min_child_weight': 2, 'reg_alpha': 0.3035077587704233, 'reg_lambda': 0.06194304527620526}. Best is trial 41 with value: 6648.874496910657.\n","[I 2023-11-15 18:41:55,641] Trial 89 finished with value: 6770.751703355265 and parameters: {'learning_rate': 0.055627116246808106, 'n_estimators': 456, 'max_depth': 7, 'max_leaves': 5, 'min_child_weight': 4, 'reg_alpha': 0.24532938827150141, 'reg_lambda': 0.09731075810311922}. Best is trial 41 with value: 6648.874496910657.\n","[I 2023-11-15 18:41:59,309] Trial 90 finished with value: 7371.879339633937 and parameters: {'learning_rate': 0.06472092510554896, 'n_estimators': 417, 'max_depth': 7, 'max_leaves': 90, 'min_child_weight': 1, 'reg_alpha': 0.15506263734749026, 'reg_lambda': 0.02886771350149154}. Best is trial 41 with value: 6648.874496910657.\n","[I 2023-11-15 18:42:00,790] Trial 91 finished with value: 6684.413631319153 and parameters: {'learning_rate': 0.06002637439342192, 'n_estimators': 534, 'max_depth': 6, 'max_leaves': 11, 'min_child_weight': 3, 'reg_alpha': 0.3964053824490758, 'reg_lambda': 0.10760697558075202}. Best is trial 41 with value: 6648.874496910657.\n","[I 2023-11-15 18:42:01,786] Trial 92 finished with value: 6711.635207755911 and parameters: {'learning_rate': 0.050466866867816894, 'n_estimators': 476, 'max_depth': 3, 'max_leaves': 7, 'min_child_weight': 3, 'reg_alpha': 0.32076831043927384, 'reg_lambda': 0.12678497238562506}. Best is trial 41 with value: 6648.874496910657.\n","[I 2023-11-15 18:42:02,821] Trial 93 finished with value: 6734.53642166242 and parameters: {'learning_rate': 0.06207132209365605, 'n_estimators': 385, 'max_depth': 8, 'max_leaves': 15, 'min_child_weight': 3, 'reg_alpha': 0.22338628551940737, 'reg_lambda': 0.053925446760018494}. Best is trial 41 with value: 6648.874496910657.\n","[I 2023-11-15 18:42:03,220] Trial 94 finished with value: 7504.095192764163 and parameters: {'learning_rate': 0.06927887724594002, 'n_estimators': 315, 'max_depth': 5, 'max_leaves': 2, 'min_child_weight': 3, 'reg_alpha': 0.28469587327629553, 'reg_lambda': 0.6851892735912237}. Best is trial 41 with value: 6648.874496910657.\n","[I 2023-11-15 18:42:04,491] Trial 95 finished with value: 6655.854905268939 and parameters: {'learning_rate': 0.05710452571880487, 'n_estimators': 505, 'max_depth': 7, 'max_leaves': 9, 'min_child_weight': 3, 'reg_alpha': 0.3378380425111776, 'reg_lambda': 0.14650651405430054}. Best is trial 41 with value: 6648.874496910657.\n","[I 2023-11-15 18:42:06,025] Trial 96 finished with value: 6804.9122171364015 and parameters: {'learning_rate': 0.05716880589336716, 'n_estimators': 445, 'max_depth': 7, 'max_leaves': 22, 'min_child_weight': 3, 'reg_alpha': 0.19295876111668034, 'reg_lambda': 0.15123284224104128}. Best is trial 41 with value: 6648.874496910657.\n","[I 2023-11-15 18:42:09,611] Trial 97 finished with value: 7457.338495129834 and parameters: {'learning_rate': 0.052756684054648104, 'n_estimators': 680, 'max_depth': 7, 'max_leaves': 0, 'min_child_weight': 2, 'reg_alpha': 0.2580323000878486, 'reg_lambda': 0.07594475711623214}. Best is trial 41 with value: 6648.874496910657.\n","[I 2023-11-15 18:42:13,143] Trial 98 finished with value: 6677.317489457603 and parameters: {'learning_rate': 0.05858120278394906, 'n_estimators': 349, 'max_depth': 8, 'max_leaves': 13, 'min_child_weight': 3, 'reg_alpha': 0.31782184512460776, 'reg_lambda': 0.7890320653245082}. Best is trial 41 with value: 6648.874496910657.\n","[I 2023-11-15 18:42:14,492] Trial 99 finished with value: 6645.677735153726 and parameters: {'learning_rate': 0.05572133661954683, 'n_estimators': 494, 'max_depth': 7, 'max_leaves': 10, 'min_child_weight': 2, 'reg_alpha': 0.28207341856080137, 'reg_lambda': 0.2089774655730952}. Best is trial 99 with value: 6645.677735153726.\n"]},{"name":"stdout","output_type":"stream","text":["Número de trials: 100\n","MAE con los mejores hiperparámetros: 6645.677735153726\n","Mejores hiperparámetros encontrados: {'learning_rate': 0.05572133661954683, 'n_estimators': 494, 'max_depth': 7, 'max_leaves': 10, 'min_child_weight': 2, 'reg_alpha': 0.28207341856080137, 'reg_lambda': 0.2089774655730952}\n"]}],"source":["import optuna\n","from sklearn.model_selection import cross_val_score\n","from sklearn.metrics import make_scorer\n","\n","# Definir la función objetivo\n","def objective(trial):\n","    params = {\n","        'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.1),\n","        'n_estimators': trial.suggest_int('n_estimators', 50, 1000),\n","        'max_depth': trial.suggest_int('max_depth', 3, 10),\n","        'max_leaves': trial.suggest_int('max_leaves', 0, 100),\n","        'min_child_weight': trial.suggest_int('min_child_weight', 1, 5),\n","        'reg_alpha': trial.suggest_float('reg_alpha', 0, 1),\n","        'reg_lambda': trial.suggest_float('reg_lambda', 0, 1)\n","    }\n","\n","    model = XGBRegressor(**params)\n","    cv_scores = cross_val_score(model, X_train_encoded, Y_train, cv=5, scoring=make_scorer(mean_absolute_error))\n","    return cv_scores.mean()  # Objetivo: minimizar el MAE en validación cruzada\n","\n","# Configurar el optimizador Optuna\n","sampler = optuna.samplers.TPESampler(seed=42)\n","study = optuna.create_study(sampler=sampler, direction='minimize')\n","study.optimize(objective, n_trials=100, timeout=300)  # Realizar 100 trials con un timeout de 5 minutos\n","\n","# Obtener los mejores hiperparámetros y su MAE asociado\n","best_params = study.best_params\n","best_mae = study.best_value\n","\n","# Entrenar el modelo final con los mejores hiperparámetros encontrados\n","best_model = XGBRegressor(**best_params)\n","best_model.fit(X_train_encoded, Y_train)\n","\n","# Guardar el mejor modelo en un archivo .pkl\n","with open('best_model_optuna.pkl', 'wb') as f:\n","    pickle.dump(best_model, f)\n","\n","# Reportar resultados\n","print(f'Número de trials: {len(study.trials)}')\n","print(f'MAE con los mejores hiperparámetros: {best_mae}')\n","print(f'Mejores hiperparámetros encontrados: {best_params}')\n"]},{"cell_type":"markdown","metadata":{"cell_id":"5195ccfc37e044ad9453f6eb2754f631","deepnote_cell_type":"markdown"},"source":["## 1.4 Optimización de Hiperparámetros con Optuna y Prunners (1.7)\n","\n","<p align=\"center\">\n","  <img src=\"https://i.pinimg.com/originals/90/16/f9/9016f919c2259f3d0e8fe465049638a7.gif\">\n","</p>\n","\n","Después de optimizar el rendimiento de su modelo varias veces, Fiu le pregunta si no es posible optimizar el entrenamiento del modelo en sí mismo. Después de leer un par de post de personas de dudosa reputación en la *deepweb*, usted llega a la conclusión que puede cumplir este objetivo mediante la implementación de **Prunning**.\n","\n","Vuelva a optimizar los mismos hiperparámetros que la sección pasada, pero esta vez utilizando **Prunning** en la optimización. En particular, usted debe:\n","\n","- Responder: ¿Qué es prunning? ¿De qué forma debería impactar en el entrenamiento?\n","- Utilizar `optuna.integration.XGBoostPruningCallback` como método de **Prunning**\n","- Fijar nuevamente el tiempo de entrenamiento a 5 minutos\n","- Reportar el número de *trials*, el `MAE` y los mejores hiperparámetros encontrados. ¿Cómo cambian sus resultados con respecto a la sección anterior? ¿A qué se puede deber esto?\n","- Guardar su modelo en un archivo .pkl\n","\n","Nota: Si quieren silenciar los prints obtenidos en el prunning, pueden hacerlo mediante el siguiente comando:\n","\n","```\n","optuna.logging.set_verbosity(optuna.logging.WARNING)\n","```\n","\n","De implementar la opción anterior, pueden especificar `show_progress_bar = True` en el método `optimize` para *más sabor*.\n","\n","Hint: Si quieren especificar parámetros del método .fit() del modelo a través del pipeline, pueden hacerlo por medio de la siguiente sintaxis: `pipeline.fit(stepmodelo__parametro = valor)`\n","\n","Hint2: Este <a href = https://stackoverflow.com/questions/40329576/sklearn-pass-fit-parameters-to-xgboost-in-pipeline>enlace</a> les puede ser de ayuda en su implementación"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"eeaa967cd8f6426d8c54f276c17dce79","deepnote_cell_type":"code"},"outputs":[],"source":["# Inserte su código acá"]},{"cell_type":"markdown","metadata":{"cell_id":"8a081778cc704fc6bed05393a5419327","deepnote_cell_type":"markdown"},"source":["## 1.5 Visualizaciones (0.5 puntos)\n","\n","<p align=\"center\">\n","  <img src=\"https://media.tenor.com/F-LgB1xTebEAAAAd/look-at-this-graph-nickelback.gif\">\n","</p>\n","\n","\n","Satisfecho con su trabajo, Fiu le pregunta si es posible generar visualizaciones que permitan entender el entrenamiento de su modelo.\n","\n","A partir del siguiente <a href = https://optuna.readthedocs.io/en/stable/tutorial/10_key_features/005_visualization.html#visualization>enlace</a>, genere las siguientes visualizaciones:\n","\n","- Gráfico de historial de optimización\n","- Gráfico de coordenadas paralelas\n","- Gráfico de importancia de hiperparámetros\n","\n","Comente sus resultados: ¿Desde qué *trial* se empiezan a observar mejoras notables en sus resultados? ¿Qué tendencias puede observar a partir del gráfico de coordenadas paralelas? ¿Cuáles son los hiperparámetros con mayor importancia para la optimización de su modelo?"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"0e706dc9a8d946eda7a9eb1f0463c6d7","deepnote_cell_type":"code"},"outputs":[],"source":["# Inserte su código acá"]},{"cell_type":"markdown","metadata":{"cell_id":"ac8a20f445d045a3becf1a518d410a7d","deepnote_cell_type":"markdown"},"source":["## 1.6 Síntesis de resultados (0.3)\n","\n","Finalmente, genere una tabla resumen del MAE obtenido en los 5 modelos entrenados (desde Baseline hasta XGBoost con Constraints, Optuna y Prunning) y compare sus resultados. ¿Qué modelo obtiene el mejor rendimiento? \n","\n","Por último, cargue el mejor modelo, prediga sobre el conjunto de test y reporte su MAE. ¿Existen diferencias con respecto a las métricas obtenidas en el conjunto de validación? ¿Porqué puede ocurrir esto?"]},{"cell_type":"markdown","metadata":{"cell_id":"5c4654d12037494fbd385b4dc6bd1059","deepnote_cell_type":"markdown"},"source":["# Conclusión\n","Eso ha sido todo para el lab de hoy, recuerden que el laboratorio tiene un plazo de entrega de una semana. Cualquier duda del laboratorio, no duden en contactarnos por mail o U-cursos.\n","\n","<p align=\"center\">\n","  <img src=\"https://media.tenor.com/8CT1AXElF_cAAAAC/gojo-satoru.gif\">\n","</p>"]},{"cell_type":"markdown","metadata":{"cell_id":"5025de06759f4903a26916c80323bf25","deepnote_cell_type":"markdown"},"source":[]},{"cell_type":"markdown","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"},"source":["<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=87110296-876e-426f-b91d-aaf681223468' target=\"_blank\">\n","<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\n","Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"]}],"metadata":{"deepnote":{},"deepnote_execution_queue":[],"deepnote_notebook_id":"f63d38450a6b464c9bb6385cf11db4d9","deepnote_persisted_session":{"createdAt":"2023-11-09T16:18:30.203Z"},"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"}},"nbformat":4,"nbformat_minor":0}
